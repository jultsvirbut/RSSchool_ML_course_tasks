{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый пункт, который предлагается выполнить в рамках домашнего задания, имеет объявленную \"цену\" в баллах. Максимально возможная сумма – 10 баллов, а с учётом бонусных пунктов – 12 баллов. Выполнять все пункты не обязательно, можно сделать только часть. В большинстве пунктов ожидается, что вы напишете работающий код на Python; иногда надо будет писать комментарии в свободной форме – например, сравнивать несколько подходов к решению одной задачи. Там, где оставлены пустые клетки под ваши ответы, вы можете по своему усмотрению добавлять ещё клетки.\n",
    "\n",
    "* * *\n",
    "\n",
    "Эта лабораторная работа посвящена кластеризации. Мы будем работать с рукописными изображениями цифр, научимся их кластеризовать двумя разными методами (иерархическая кластеризация и алгоритм $K$-means), оценивать качество разбиения и выбирать оптимальное число кластеров, а также визуализировать промежуточные результаты.\n",
    "\n",
    "# 1. Получение данных\n",
    "\n",
    "Данные, с которыми мы будем работать, доступны в библиотеке scikit-learn (модуль называется `sklearn`) в подмодуле `datasets` через функцию, которая называется `load_digits`. Всего имеется 1797 наблюдений, каждое из них представляет чёрно-белую картинку 8 $\\times$ 8 пикселей. Эти картинки – распознанные рукописные цифры от 0 до 9. Образцов написания каждой цифры дано приблизительно поровну, около 180.\n",
    "\n",
    "Для удобства использования данных каждая картинка \"развёрнута\" в строку, так что NumPy-массив, в котором хранятся данные, имеет размерность 2 и величину 1797 $\\times$ 64 (а не, например, размерность 3 и величину 1797 $\\times$ 8 $\\times$ 8). Интенсивность цвета в каждом пикселе кодируется целым числом от 0 до 16.\n",
    "\n",
    "Кроме наблюдений (картинок), известны соответствующие им значения целевой переменной: какую цифру на самом деле изображает каждая картинка. Мы могли бы сразу сформулировать задачу обучения с учителем и предсказывать цифры по картинкам, но для целей этой лабораторной работы мы будем действовать по-другому: сделаем вид, что нам не известны истинные метки классов (т. е. цифры) и даже количество классов, и попробуем сгруппировать данные таким образом, чтобы качество кластеризации оказалось наилучшим, а затем посмотрим, насколько точно полученные кластеры совпадают с группами изображений одинаковых цифр.\n",
    "\n",
    "**(0.5 балла)** Загрузите данные. Добейтесь, чтобы в переменной `X` оказался массив наблюдений, содержащий 1797 $\\times$ 64 числа, а в переменной `y` – массив истинных меток классов, содержащий 1797 чисел.\n",
    "\n",
    "*Указания:*\n",
    "- Как загрузить данные, объяснено в справке к функции `load_digits`.\n",
    "- Размер массива хранится в атрибуте `shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1797, 64), shape of y (1797,)\n"
     ]
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "X = digits['data']\n",
    "y = digits['target']\n",
    "print(\"Shape of X: {}, shape of y {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл)** Визуализируйте первые десять картинок, расположив их на сетке 3 $\\times$ 4 (в последнем ряду останутся пустые места). Добейтесь, чтобы фон картинок был белым, а изображения цифр – тёмными.\n",
    "\n",
    "*Указания:*\n",
    "- Не забудьте импортировать NumPy и Matplotlib.\n",
    "- Картинки 8 $\\times$ 8 можно либо достать готовыми из объекта, загруженного функцией `load_digits`, либо сделать самостоятельно из строк массива `X`. Во втором случае пользуйтесь методом `reshape`.\n",
    "- Чтобы изображение не было цветным, можно вызвать функцию `plt.gray`, прежде чем начать рисовать.\n",
    "- Располагать картинки на сетке умеет функция `plt.subplot`. Ознакомьтесь со справкой к ней.\n",
    "- По умолчанию число 0 кодирует чёрный цвет, а число 16 – белый цвет. Подумайте, как обратить цвета одной операцией над NumPy-массивом.\n",
    "- Выводить картинку на экран умеет функция `plt.imshow`. Ознакомьтесь со справкой к ней.\n",
    "- Если считаете нужным, можете отключить сглаживание – параметр `interpolation` у функции `plt.imshow`.\n",
    "- Если считаете нужным, можете отключить деления на координатных осях. За это отвечают функции `plt.xticks` и `plt.yticks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_row = 3\n",
    "num_col = 4\n",
    "\n",
    "fig, axs = plt.subplots(num_row, num_col, facecolor='white')\n",
    "plt.gray() \n",
    "#ax.set_facecolor('xkcd:salmon')\n",
    "\n",
    "plt.setp(axs, xticks=[], yticks=[])\n",
    "\n",
    "for i in range(len(digits.images[:10])):\n",
    "    ax = axs[i//num_col, i%num_col]\n",
    "    indices_non_zero = digits.images[i] > 13.\n",
    "    indices_zero = digits.images[i] == 0.\n",
    "    digits.images[i][indices_non_zero] = 0.\n",
    "    digits.images[i][indices_zero] = 16.\n",
    "    ax.imshow(digits.images[i], interpolation=None) \n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.xticks(ticks=None)\n",
    "plt.yticks(ticks=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Кластеризация и оценка качества\n",
    "\n",
    "Мы будем использовать два популярных алгоритма: иерархическую кластеризацию и метод $K$ средних ($K$-means clustering). Эти и другие алгоритмы кластеризации доступны в библиотеке scikit-learn в подмодуле `cluster`. Иерархическая кластеризация называется `AgglomerativeClustering`, а метод $K$ средних – `KMeans`.\n",
    "\n",
    "Интерфейс у большинства алгоритмов в scikit-learn простой и единообразный:\n",
    "- Чтобы инициализировать модель, нужно создать экземпляр соответствующего класса со всеми необходимыми параметрами. Например, у кластеризаций единственный обязательный параметр называется `n_clusters`, это количество кластеров, которое мы хотим получить на выходе.\n",
    "- Инициализированную модель можно обучить, вызвав метод `fit`.\n",
    "- С помощью обученной модели можно предсказывать, вызывая метод `predict`.\n",
    "\n",
    "Как видно, этот интерфейс хорош только для задач обучения с учителем, в которых чётко разделены фазы обучения модели и предсказания с её помощью. У кластеризаций зато есть метод `fit_predict`, который разбивает входную выборку на кластеры и сразу же возвращает результаты разбиения.\n",
    "\n",
    "**(0.5 балла)** Используя каждый из двух методов, иерархическую кластеризацию и $K$ средних, получите разбиение массива `X` на 10 кластеров.\n",
    "\n",
    "*Указания:*\n",
    "- Оба раза должен получиться массив из 1797 чисел – номеров кластеров.\n",
    "- `KMeans` делает несколько (по умолчанию 10) запусков со случайными центрами и из полученных разбиений выводит лучшее в терминах среднего внутрикластерного расстояния. Чтобы улучшить качество предсказаний, можно увеличить число запусков, например, до 100. Это параметр `n_init` в конструкторе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering, KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 8, ..., 0, 4, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hier = AgglomerativeClustering(n_clusters=10)\n",
    "model_hier.fit_predict(X)\n",
    "model_hier.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_hier.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 4, ..., 9, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kmean = KMeans(n_clusters=10)\n",
    "model_kmean.fit_predict(X)\n",
    "model_kmean.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_kmean.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл)** Визуализируйте центры кластеров, полученных каждым из двух способов. Это опять должны быть картинки на сетке 3 $\\times$ 4 с белым фоном и тёмными контурами. Прокомментируйте: какой из двух алгоритмов даёт центры кластеров, больше похожие на типичные начертания цифр?\n",
    "\n",
    "*Указания:*\n",
    "- Центр кластера – это среднее по всем наблюдениям, входящим в кластер, т. е. по какому-то набору строк из `X`.\n",
    "- Чтобы выбрать наблюдения, входящие в кластер номер `i`, используйте индексацию по булевозначной маске. Саму маску можно получить из массива предсказанных номеров кластеров и числа `i` оператором `==`.\n",
    "- Усреднять NumPy-массив вдоль какой-нибудь из осей умеет функция `np.mean`. Ознакомьтесь со справкой к ней. Нам нужно усреднение по строкам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kmean.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2, 5, figsize=(8, 3))\n",
    "centers = model_kmean.cluster_centers_.reshape(10, 8, 8)\n",
    "for axi, center in zip(ax.flat, centers):\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.imshow(center, interpolation='nearest', cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ситуации, когда истинное число кластеров неизвестно, подбирают оптимальное число кластеров. При этом учитывают две величины: внутрикластерное расстояние (чем меньше, тем лучше) и межкластерное расстояние (чем больше, тем лучше). Так как две эти величины не достигают оптимума одновременно, обычно оптимизируют какой-нибудь функционал от них. Один популярный функционал называется \"силуэт\" (silhouette). Вот как он вычисляется.\n",
    "\n",
    "Пусть $X$ – множество наблюдений, $M \\subset X$ – один из кластеров, на которые оно разбито в результате кластеризации, $\\rho$ – метрика на $X$. Выберем какое-нибудь одно наблюдение $x \\in M$. Обозначим $a(x)$ среднее расстояние от $x$ до точек $x'$ из того же кластера:\n",
    "$$\n",
    "a(x) = \\frac{1}{|M| - 1} \\sum_{x' \\in M,\\, x' \\ne x} \\rho(x,\\, x')\n",
    "$$\n",
    "\n",
    "Обозначим $b(x)$ минимум средних расстояний от $x$ до точек $x''$ из какого-нибудь другого кластера $N$:\n",
    "$$\n",
    "b(x) = \\min_{N \\ne M} \\frac{1}{|N|} \\sum_{x'' \\in N} \\rho(x,\\, x'')\n",
    "$$\n",
    "\n",
    "Силуэт – это разность межкластерного и внутрикластерного расстояний, нормированная до отрезка $[-1,\\, 1]$ и усреднённая по всем наблюдениям:\n",
    "$$\n",
    "\\frac{1}{|X|} \\sum_{x \\in X} \\frac{b(x) - a(x)}{\\max(a(x),\\, b(x))}\n",
    "$$\n",
    "\n",
    "В scikit-learn силуэт считается функцией `silhouette_score` из подмодуля `metrics`. На вход нужно передать массив наблюдений и результат кластеризации.\n",
    "\n",
    "**(1.5 балла)** Для числа $K$ от 2 до 20 включительно получите разбиение массива `X` на $K$ кластеров каждым из двух методов. Посчитайте силуэт. Посчитанные значения силуэта сохраните в переменную и визуализируйте в виде графика в координатах: число $K$ – значение силуэта. При каком числе кластеров достигается максимум силуэта?\n",
    "\n",
    "*Указания:*\n",
    "- Не забудьте, что функция `range` не захватывает правый конец диапазона.\n",
    "- Под значения силуэта можно завести два списка: один для иерархической кластеризации, другой для $K$ средних.\n",
    "- Рисовать графики умеет функция `plt.plot`. Ознакомьтесь со справкой к ней.\n",
    "- На одной картинке можно разместить несколько графиков, это просто несколько последовательных вызовов `plt.plot`.\n",
    "- Чтобы добавить легенду (подписи к графикам), можно воспользоваться функцией `plt.legend`. Местоположение легенды контролируется параметром `loc`.\n",
    "- Чтобы подписать координатные оси, можно воспользоваться функциями `plt.xlabel` и `plt.ylabel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда известно \"правильное\" (в каком-нибудь смысле) разбиение на кластеры, результат кластеризации можно сравнить с ним, используя такие меры, как однородность (homogeneity), полнота (completeness) и их среднее гармоническое – $V$-мера. Определения этих величин довольно громоздкие и основаны на понятии [энтропии распределения вероятностей](https://ru.wikipedia.org/wiki/Информационная_энтропия); подробности излагаются в [этой статье](http://aclweb.org/anthology/D/D07/D07-1043.pdf). На практике достаточно знать, что однородность, полнота и $V$-мера заключены между нулём и единицей – чем больше, тем лучше.\n",
    "\n",
    "Так как мы знаем, какую цифру на самом деле изображает каждая картинка (это массив `y`), мы можем использовать однородность, полноту и $V$-меру для оценки качества кластеризации. Функции для вычисления этих величин доступны в scikit-learn, в подмодуле `metrics`, под названиями `homogeneity_score`, `completeness_score`, `v_measure_score`. Как вариант, можно использовать функцию `homogeneity_completeness_v_measure`, которая возвращает сразу тройку чисел.\n",
    "\n",
    "**(1 балл)** Повторите предыдущее задание, используя $V$-меру вместо силуэта. При каком числе кластеров достигается максимум $V$-меры?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Снижение размерности признакового пространства\n",
    "\n",
    "Иногда, особенно когда признаков много и не все они одинаково информативные, бывает полезно снизить размерность признакового пространства, то есть вместо $d$ исходных признаков перейти к рассмотрению $d' \\ll d$ новых признаков. Данные были представлены матрицей $n$ наблюдений $\\times$ $d$ исходных признаков, а теперь будут представлены матрицей $n$ наблюдений $\\times$ $d'$ новых признаков.\n",
    "\n",
    "Есть два популярных подхода к снижению размерности:\n",
    "- отобрать (select) новые признаки из числа имеющихся;\n",
    "- извлечь (extract) новые признаки, преобразуя старые, например, сделать $d'$ различных линейных комбинаций столбцов исходной матрицы $n \\times d$.\n",
    "\n",
    "Одним из широко используемых методов извлечения признаков является сингулярное разложение матрицы (singular value decomposition, SVD). Этот метод позволяет сконструировать любое число $d' \\le d$ новых признаков таким образом, что они будут, в определённом смысле, максимально информативными. Математические детали сейчас не важны; познакомиться с ними можно, например, [здесь](https://www.coursera.org/learn/mathematics-and-python/lecture/L9bCV/razlozhieniia-matrits-v-proizviedieniie-singhuliarnoie-razlozhieniie)\n",
    "(по-русски) или [здесь](https://www.youtube.com/watch?v=P5mlg91as1c) (по-английски).\n",
    "\n",
    "В scikit-learn есть несколько реализаций сингулярного разложения. Мы будем использовать класс `TruncatedSVD` из подмодуля `decomposition`. В конструктор этого класса достаточно передать один параметр `n_components` – желаемое число новых признаков. Метод `fit_transform` принимает матрицу и возвращает новую матрицу с таким же количеством строк, как прежде, и количеством столбцов, равным числу новых признаков.\n",
    "\n",
    "<u>Замечание:</u> Сингулярное разложение матрицы $M$ обычно пишут в виде $M = U \\Sigma V^{*}$, где $U$, $\\Sigma$ и $V$ – некие матрицы с хорошими свойствами. То, что возвращает алгоритм `TruncatedSVD`, – это сколько-то (сколько мы хотим получить) первых столбцов матрицы $U$.\n",
    "\n",
    "**(1.5 балла)** Выполните сингулярное разложение матрицы `X`, оставляя 2, 5, 10, 20 признаков. В каждом случае выполните иерархическую и $K$-means кластеризацию преобразованных данных (число кластеров примите равным 10). Посчитайте значения силуэта и $V$-меры. Удалось ли при каком-нибудь $d'$ получить силуэт и / или $V$-меру лучше, чем на исходных данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другая популярная техника снижения размерности, которая особенно хорошо подходит для работы с картинками, – это алгоритм t-distributed stochastic neighbor embeddings, сокращённо tSNE. В отличие от сингулярного разложения, это преобразование нелинейное. Его основная идея – отобразить точки из пространства размерности $d$ в пространство размерности 2 или 3 (обычно 2, то есть на плоскость) таким образом, чтобы как можно точнее сохранить расстояния. Математические детали есть, например, [здесь](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding), но они нетривиальны.\n",
    "\n",
    "В библиотеке scikit-learn реализацией tSNE является класс `TSNE` в подмодуле `manifold`. В конструктор можно передать параметр `n_components`, а можно и не передавать: по умолчанию он равен 2. Метод `fit_transform` работает аналогично тому, как и у `TruncatedSVD`.\n",
    "\n",
    "<u>Замечание:</u> В последние годы вместо tSNE на практике часто используется [UMAP](https://github.com/lmcinnes/umap), более быстрый алгоритм с похожими свойствами. В этой лабораторной работе не предлагается использовать UMAP, так как это потребовало бы установить ещё одну зависимость -- библиотеку `umap-learn`. Желающие могут проделать задания на tSNE с использованием UMAP; в этом случае обратите внимание на параметры `n_neighbors` и `min_dist`, которыми определяется вид проекции.\n",
    "\n",
    "**(0.5 балла)** Выполните tSNE-преобразование матрицы `X`, оставив 2 признака. Визуализируйте данные, преобразованные таким образом, в виде точечной диаграммы: первый признак вдоль горизонтальной оси, второй признак вдоль вертикальной оси. Подсветите разными цветами группы точек, соответствующих разным цифрам.\n",
    "\n",
    "*Указания:*\n",
    "- Точечную диаграмму умеет рисовать функция `plt.scatter`. Ознакомьтесь со справкой к ней.\n",
    "- За цвета точек отвечает параметр `c` у функции `plt.scatter`. Передать в него надо истинные метки классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл)** Для tSNE-преобразованных данных с 2 признаками выполните иерархическую и $K$-means кластеризацию (число кластеров примите равным 10). Посчитайте значения силуэта и $V$-меры. Удалось ли получить силуэт и / или $V$-меру лучше, чем на исходных данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 балла)** Для самого лучшего разбиения, которое вам удалось получить (на ваше усмотрение, лучшего в терминах силуэта или $V$-меры), опять визуализируйте картинками центры кластеров. Удалось ли добиться, чтобы каждый кластер соответствовал какой-нибудь одной цифре?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Итоги, бонус\n",
    "\n",
    "**(1 балл)** Напишите в свободной форме, какие выводы вы сделали из выполненной работы. Ответьте, как минимум, на следующие два вопроса:\n",
    "- Какой из двух методов даёт более осмысленные кластеры – иерархическая кластеризация или алгоритм $K$ средних? Зависит ли это от настроек каждого алгоритма? От критериев оценивания качества?\n",
    "- Удаётся ли улучшить качество кластеризации, снижая размерность признакового пространства?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Бонусные 2 балла)** Скачайте датасет [MNIST Handwritten Digits](http://yann.lecun.com/exdb/mnist). Как сделать это с помощью scikit-learn, написано [здесь](https://stackoverflow.com/a/60450028). MNIST Handwritten Digits – это 70 тысяч распознанных рукописных изображений цифр, каждое размером 28 $\\times$ 28 пикселей. Попробуйте прокластеризовать этот датасет и добиться как можно лучших значений силуэта и $V$-меры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
